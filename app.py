from flask import Flask, render_template, request, redirect, url_for
import json
import os
import asyncio
import csv
import io
import threading
from main_analyzer import run_analysis

app = Flask(__name__)
# ã‚»ãƒƒã‚·ãƒ§ãƒ³é€šçŸ¥ç”¨ã«ã‚­ãƒ¼ã‚’è¨­å®šï¼ˆå¿…é ˆã§ã¯ãªã„ã§ã™ãŒå¿µã®ãŸã‚ï¼‰
app.secret_key = 'cosplay_analysis_secret'
DB_FILE = 'analysis_db.json'

def load_data():
    """ JSONãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã‚€ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° """
    if os.path.exists(DB_FILE):
        with open(DB_FILE, 'r', encoding='utf-8') as f:
            try: return json.load(f)
            except: return []
    return []

# --- ğŸ§µ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ç”¨ã®é–¢æ•° ---
def background_batch_analysis(urls):
    """ è£å´ï¼ˆåˆ¥ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰ã§å®Ÿè¡Œã•ã‚Œã‚‹åˆ†æãƒ«ãƒ¼ãƒ— """
    print(f"ğŸ§µ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã‚’é–‹å§‹: å…¨ {len(urls)} ä»¶")
    
    # ã‚¹ãƒ¬ãƒƒãƒ‰ã”ã¨ã«æ–°ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    
    for i, url in enumerate(urls):
        # é€²æ—ã‚’ãƒ­ã‚°ã«å‡ºã™ï¼ˆã“ã‚ŒãŒã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§è¦‹ãˆã‚‹ï¼‰
        print(f"ğŸ“¦ Batch Progress: {i+1}/{len(urls)} -> {url}")
        try:
            # main_analyzer.py ã®å‡¦ç†ã‚’å‘¼ã³å‡ºã™
            # (main_analyzerå´ã«ã‚¹ã‚­ãƒƒãƒ—æ©Ÿèƒ½ãŒã‚ã‚‹ã®ã§ã€æ—¢ã«çµ‚ã‚ã£ã¦ã„ã‚Œã°ä¸€ç¬ã§æ¬¡ã¸é€²ã¿ã¾ã™)
            loop.run_until_complete(run_analysis(url))
        except Exception as e:
            print(f"âŒ Error in batch: {url} -> {e}")
    
    print("ğŸ ã™ã¹ã¦ã®ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    loop.close()

@app.route('/', methods=['GET'])
def index():
    """ ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸: æœ€æ–°ã®åˆ†æçµæœãƒªã‚¹ãƒˆã‚’è¡¨ç¤º """
    data = load_data()
    data.reverse() # æ–°ã—ã„é †
    return render_template('index.html', tweets=data)

@app.route('/analyze', methods=['POST'])
def analyze():
    """ å˜ç™ºåˆ†æç”¨ """
    url = request.form.get('url')
    if url:
        print(f"ğŸš€ å˜ç™ºãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {url}")
        asyncio.run(run_analysis(url))
    return redirect(url_for('index'))

@app.route('/upload_csv', methods=['POST'])
def upload_csv():
    """ CSVä¸€æ‹¬åˆ†æç”¨ï¼ˆã‚¹ãƒ¬ãƒƒãƒ‰å¯¾å¿œç‰ˆï¼‰ """
    if 'file' not in request.files:
        return redirect(url_for('index'))
    
    file = request.files['file']
    if file.filename == '' or not file:
        return redirect(url_for('index'))

    # CSVã‹ã‚‰URLãƒªã‚¹ãƒˆã‚’ä½œæˆ
    stream = io.StringIO(file.stream.read().decode("UTF8"), newline=None)
    csv_input = csv.reader(stream)
    
    # x.com ã¾ãŸã¯ twitter.com ã‚’å«ã‚€URLã ã‘æŠ½å‡º
    urls = [row[0].strip() for row in csv_input if row and ("x.com" in row[0] or "twitter.com" in row[0])]

    if urls:
        # â˜…ã“ã“ãŒé‡è¦ï¼
        # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’æ­¢ã‚ãªã„ã‚ˆã†ã«ã€åˆ¥ã®ã‚¹ãƒ¬ãƒƒãƒ‰ï¼ˆåˆ†èº«ï¼‰ã‚’ä½œã£ã¦ä»•äº‹ã‚’ä¸¸æŠ•ã’ã™ã‚‹
        thread = threading.Thread(target=background_batch_analysis, args=(urls,))
        thread.start()
        
        print(f"âœ… {len(urls)} ä»¶ã®åˆ†æã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§äºˆç´„ã—ã¾ã—ãŸã€‚")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚’å¾…ãŸã›ãšã«å³åº§ã«ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã¸æˆ»ã™
    return redirect(url_for('index'))

@app.route('/stats', methods=['GET'])
def stats():
    """ åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”¨ï¼ˆ4è±¡é™ãƒãƒˆãƒªã‚¯ã‚¹å¯¾å¿œï¼‰ """
    data = load_data()
    
    if not data:
        return render_template('stats.html', stats=None)

    # --- çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®è¨ˆç®— ---
    stats_data = {
        "total_tweets": len(data),
        "avg_save_rate": 0,
        "avg_eng_rate": 0,
        "composition_stats": {},
        "brightness_stats": {},
        "top_tweets": [],
        "scatter_data": [] # æ•£å¸ƒå›³ç”¨ã®ãƒ‡ãƒ¼ã‚¿
    }

    # 1. å…¨ä½“å¹³å‡ã®è¨ˆç®—
    if len(data) > 0:
        total_save = sum(d.get('save_rate', 0) for d in data)
        total_eng = sum(d.get('engagement_rate', 0) for d in data)
        stats_data['avg_save_rate'] = round(total_save / len(data), 2)
        stats_data['avg_eng_rate'] = round(total_eng / len(data), 2)

    # 2. ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆï¼ˆæ§‹å›³ãƒ»æ˜ã‚‹ã•ï¼‰
    # ãƒ«ãƒ¼ãƒ—ã‚’1å›ã«ã¾ã¨ã‚ã¦é«˜é€ŸåŒ–
    comp_groups = {}
    bright_groups = {}
    
    for d in data:
        # ç”»åƒãŒãªã„ãƒ‡ãƒ¼ã‚¿ã¯ã‚¹ã‚­ãƒƒãƒ—
        if not d.get('images'): continue
        
        # æ§‹å›³é›†è¨ˆ
        comp = d['images'][0].get('composition', 'Unknown')
        if comp not in comp_groups: comp_groups[comp] = []
        comp_groups[comp].append(d.get('save_rate', 0))
        
        # æ˜ã‚‹ã•é›†è¨ˆ
        bright = d['images'][0].get('brightness', 'Unknown')
        if bright not in bright_groups: bright_groups[bright] = []
        bright_groups[bright].append(d.get('engagement_rate', 0))
        
        # â˜…æ•£å¸ƒå›³ç”¨ã®ãƒ‡ãƒ¼ã‚¿ä½œæˆ (X:Eng, Y:Save)
        stats_data['scatter_data'].append({
            'x': d.get('engagement_rate', 0),
            'y': d.get('save_rate', 0),
            'id': d.get('tweet_id'),
            'url': d.get('url'),
            'img': d['images'][0]['path'] # ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ç”»åƒç”¨
        })
    
    # å¹³å‡å€¤ã®ç®—å‡º
    stats_data['composition_stats'] = {k: round(sum(v)/len(v), 2) for k, v in comp_groups.items()}
    stats_data['brightness_stats'] = {k: round(sum(v)/len(v), 2) for k, v in bright_groups.items()}

    # 4. ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¿å­˜ç‡TOP5ï¼‰
    stats_data['top_tweets'] = sorted(data, key=lambda x: x.get('save_rate', 0), reverse=True)[:5]

    return render_template('stats.html', stats=stats_data)

if __name__ == '__main__':
    # å¤–éƒ¨å…¬é–‹è¨­å®š
    app.run(host='0.0.0.0', port=5000, debug=True)