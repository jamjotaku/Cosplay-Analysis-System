import os
import json
import asyncio
import csv
from flask import Flask, render_template, request, redirect, url_for
from werkzeug.utils import secure_filename
from datetime import datetime

# main_analyzer.py ã‹ã‚‰åˆ†æãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# â€» main_analyzer.py ãŒåŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹å‰æã§ã™
from main_analyzer import run_analysis

app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['DB_FILE'] = 'analysis_db.json'
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# ---------------------------------------------------------
# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ & ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ---------------------------------------------------------
def load_data():
    if os.path.exists(app.config['DB_FILE']):
        with open(app.config['DB_FILE'], 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except:
                return []
    return []

def background_batch_analysis(csv_path):
    """ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§CSVã®URLã‚’é †æ¬¡å‡¦ç†ã™ã‚‹ """
    urls = []
    try:
        with open(csv_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # 'Expanded URL' ã¾ãŸã¯ 'URL' ã‚«ãƒ©ãƒ ã‚’æ¢ã™
                url = row.get('Expanded URL') or row.get('URL')
                if url:
                    urls.append(url)
    except Exception as e:
        print(f"âŒ CSV Read Error: {e}")
        return

    print(f"ğŸš€ Batch Analysis Started: {len(urls)} tweets")
    for i, url in enumerate(urls):
        print(f"Processing {i+1}/{len(urls)}: {url}")
        asyncio.run(run_analysis(url))
    print("ğŸ‰ All Batch Analysis Completed!")

# ---------------------------------------------------------
# ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
# ---------------------------------------------------------
@app.route('/')
def index():
    """ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ (ä¸€è¦§ç”»é¢) """
    data = load_data()
    # æ–°ã—ã„é †ã«ä¸¦ã³æ›¿ãˆ
    data.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
    return render_template('index.html', tweets=data)

@app.route('/upload_csv', methods=['POST'])
def upload_csv():
    """ CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è§£æé–‹å§‹ """
    if 'file' not in request.files:
        return redirect(url_for('index'))
    file = request.files['file']
    if file.filename == '':
        return redirect(url_for('index'))

    if file:
        filename = secure_filename(file.filename)
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)

        # éåŒæœŸã§è§£æã‚’å®Ÿè¡Œ (ç°¡æ˜“çš„ãªå®Ÿè£…)
        import threading
        thread = threading.Thread(target=background_batch_analysis, args=(filepath,))
        thread.start()

        return redirect(url_for('index'))

@app.route('/stats')
def stats():
    """ â˜…åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”»é¢ (å®Œå…¨ç‰ˆ) """
    data = load_data()
    if not data:
        return render_template('stats.html', stats=None)

    # --- é›†è¨ˆç”¨ãƒ‡ãƒ¼ã‚¿ã®åˆæœŸåŒ– ---
    stats_data = {
        "total_tweets": len(data),
        "avg_save_rate": 0,
        "avg_eng_rate": 0,
        "composition_stats": {}, # æ§‹å›³åˆ¥å¹³å‡
        "hourly_stats": [0] * 24, # 0æ™‚~23æ™‚ã®å¹³å‡ä¿å­˜ç‡
        "scatter_data": [],       # ãƒ¡ã‚¤ãƒ³ãƒãƒˆãƒªã‚¯ã‚¹ç”¨
        "skin_scatter": []        # è‚Œè‰²ç‡ vs ä¿å­˜ç‡ç”¨
    }

    hourly_sums = [0] * 24
    hourly_counts = [0] * 24
    comp_groups = {}

    total_save_rate = 0
    total_eng_rate = 0

    for d in data:
        save_rate = d.get('save_rate', 0)
        eng_rate = d.get('engagement_rate', 0)
        total_save_rate += save_rate
        total_eng_rate += eng_rate
        
        # 1. ãƒãƒˆãƒªã‚¯ã‚¹ç”¨ãƒ‡ãƒ¼ã‚¿
        img_path = ""
        comp_cat = "Unknown"
        skin_ratio = 0
        
        if d.get('images'):
            img_data = d['images'][0]
            img_path = img_data.get('path', '')
            comp_cat = img_data.get('composition', 'Unknown')
            skin_ratio = img_data.get('skin_ratio', 0)

        stats_data['scatter_data'].append({
            'x': eng_rate,
            'y': save_rate,
            'id': d.get('tweet_id'),
            'img': img_path
        })

        # 2. â˜…è‚Œè‰²ç‡ãƒ‡ãƒ¼ã‚¿ (æ§‹å›³æƒ…å ±ã‚‚å«ã‚ã‚‹ã®ãŒãƒã‚¤ãƒ³ãƒˆ)
        # ç”»åƒãŒã‚ã‚Šã€ã‹ã¤è‚Œè‰²ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿
        if d.get('images'):
            stats_data['skin_scatter'].append({
                'x': skin_ratio,
                'y': save_rate,
                'comp': comp_cat  # â˜…ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§è‰²åˆ†ã‘ã™ã‚‹ãŸã‚ã«å¿…é ˆ
            })

        # 3. æ™‚é–“å¸¯ãƒ‡ãƒ¼ã‚¿ (ISOå½¢å¼ã®æ—¥æ™‚æ–‡å­—åˆ—ã‹ã‚‰æ™‚é–“ã‚’æŠ½å‡º)
        created_at = d.get('created_at')
        if created_at:
            try:
                # "2026-02-10T19:30:00" -> 19
                hour = int(created_at.split('T')[1].split(':')[0])
                hourly_sums[hour] += save_rate
                hourly_counts[hour] += 1
            except:
                pass

        # 4. æ§‹å›³åˆ¥ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
        if comp_cat not in comp_groups:
            comp_groups[comp_cat] = []
        comp_groups[comp_cat].append(save_rate)

    # --- å¹³å‡å€¤ã®è¨ˆç®— ---
    if len(data) > 0:
        stats_data['avg_save_rate'] = round(total_save_rate / len(data), 2)
        stats_data['avg_eng_rate'] = round(total_eng_rate / len(data), 2)

    # æ™‚é–“å¸¯åˆ¥å¹³å‡
    for h in range(24):
        if hourly_counts[h] > 0:
            stats_data['hourly_stats'][h] = round(hourly_sums[h] / hourly_counts[h], 2)

    # æ§‹å›³åˆ¥å¹³å‡
    stats_data['composition_stats'] = {
        k: round(sum(v)/len(v), 2) for k, v in comp_groups.items()
    }

    return render_template('stats.html', stats=stats_data)

if __name__ == '__main__':
    app.run(debug=True, port=5000)