import os
import json
import asyncio
import csv
import threading
from flask import Flask, render_template, request, redirect, url_for
from main_analyzer import run_analysis

app = Flask(__name__)
app.config['DB_FILE'] = 'analysis_db.json'
app.config['UPLOAD_FOLDER'] = 'uploads'
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

def load_data():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰è§£ææ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    if os.path.exists(app.config['DB_FILE']):
        with open(app.config['DB_FILE'], 'r', encoding='utf-8') as f:
            try:
                return json.load(f)
            except:
                return []
    return []

# --- ğŸš€ è§£æãƒ­ã‚¸ãƒƒã‚¯ç¾¤ ---

def background_batch_analysis(csv_path):
    """CSVã®å…¨URLã‚’è£å´ã§1ä»¶ãšã¤è§£æã™ã‚‹ (504ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–)"""
    urls = []
    try:
        with open(csv_path, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            for row in reader:
                # æŸ”è»Ÿãªã‚«ãƒ©ãƒ åå¯¾å¿œ
                url = row.get('Expanded URL') or row.get('URL')
                if url:
                    urls.append(url)
    except Exception as e:
        print(f"âŒ CSV Read Error: {e}")
        return

    print(f"ğŸš€ CSV Batch Start: {len(urls)} items")
    for i, url in enumerate(urls):
        try:
            # å„URLã«å¯¾ã—ã¦éåŒæœŸè§£æã‚’å®Ÿè¡Œ
            asyncio.run(run_analysis(url))
        except Exception as e:
            print(f"âš ï¸ Skip {url} due to error: {e}")
            continue
    print("ğŸ‰ All tasks finished!")

@app.route('/analyze_single', methods=['POST'])
def analyze_single():
    """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šç‰¹å®šã®URLã‚’1ä»¶ã ã‘ãã®å ´ã§è§£æã™ã‚‹"""
    url = request.form.get('url')
    if url:
        asyncio.run(run_analysis(url))
    return redirect(url_for('index'))

@app.route('/upload_csv', methods=['POST'])
def upload_csv():
    """CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ä¸€æ‹¬è§£æã‚’é–‹å§‹ã™ã‚‹"""
    file = request.files.get('file')
    if file and file.filename.endswith('.csv'):
        path = os.path.join(app.config['UPLOAD_FOLDER'], file.filename)
        file.save(path)
        # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’åˆ†é›¢ã—ã¦å³åº§ã«ç”»é¢ã‚’è¿”ã™
        threading.Thread(target=background_batch_analysis, args=(path,)).start()
    return redirect(url_for('index'))

# --- ğŸ“Š è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ç¾¤ ---

@app.route('/')
def index():
    """è§£ææ¸ˆã¿ãƒ„ã‚¤ãƒ¼ãƒˆã®ã‚«ãƒ¼ãƒ‰ä¸€è¦§ã‚’è¡¨ç¤º"""
    data = load_data()
    # æœ€æ–°ã®è§£æçµæœãŒä¸Šã«ãã‚‹ã‚ˆã†ã«ã‚½ãƒ¼ãƒˆ
    data.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
    return render_template('index.html', tweets=data)

@app.route('/stats')
def stats():
    """ã‚°ãƒ©ãƒ•ãŠã‚ˆã³æ·±æ˜ã‚Šãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    data = load_data()
    if not data:
        return render_template('stats.html', stats=None)
    
    stats_data = {
        "total_tweets": len(data),
        "avg_save_rate": 0,
        "avg_eng_rate": 0,
        "hourly_stats": [0] * 24,
        "scatter_data": [],
        "skin_scatter": [],
        "raw_tweets": data  # æ·±æ˜ã‚Šç”¨ã«ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ãƒ­ãƒ³ãƒˆã«æ¸¡ã™
    }
    
    h_sums, h_counts = [0]*24, [0]*24
    total_s, total_e = 0, 0
    
    for d in data:
        s_rate = d.get('save_rate', 0)
        e_rate = d.get('engagement_rate', 0)
        total_s += s_rate
        total_e += e_rate
        
        img = d['images'][0] if d.get('images') else {}
        comp = img.get('composition', 'Unknown')
        
        # 4è±¡é™ãƒãƒˆãƒªã‚¯ã‚¹ç”¨ãƒ‡ãƒ¼ã‚¿
        stats_data['scatter_data'].append({
            'x': e_rate, 
            'y': s_rate, 
            'id': d.get('tweet_id')
        })
        
        # è‚Œè‰²éœ²å‡ºåº¦åˆ†æç”¨ (è‰²åˆ†ã‘ã®ãŸã‚ã®æ§‹å›³æƒ…å ±ã‚’ä»˜ä¸)
        if 'skin_ratio' in img:
            stats_data['skin_scatter'].append({
                'x': img['skin_ratio'], 
                'y': s_rate, 
                'comp': comp
            })
            
        # Snowflakeæ™‚åˆ»ã‹ã‚‰æ™‚é–“å¸¯ã‚’é›†è¨ˆ
        c_at = d.get('created_at')
        if c_at and 'T' in c_at:
            try:
                hour = int(c_at.split('T')[1].split(':')[0])
                h_sums[hour] += s_rate
                h_counts[hour] += 1
            except:
                pass

    # å¹³å‡å€¤ã®ç®—å‡º
    stats_data['avg_save_rate'] = round(total_s / len(data), 2)
    stats_data['avg_eng_rate'] = round(total_e / len(data), 2)
    
    for h in range(24):
        if h_counts[h] > 0:
            stats_data['hourly_stats'][h] = round(h_sums[h] / h_counts[h], 2)
    
    return render_template('stats.html', stats=stats_data)

@app.route('/clear_db')
def clear_db():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    if os.path.exists(app.config['DB_FILE']):
        os.remove(app.config['DB_FILE'])
    return redirect(url_for('index'))

if __name__ == '__main__':
    app.run(debug=True, port=5000)