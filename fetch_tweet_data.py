import sys
import asyncio
import json
import re
from datetime import datetime
from playwright.async_api import async_playwright

# --- Ë®≠ÂÆö ---
AUTH_FILE = 'auth.json'  # „É≠„Ç∞„Ç§„É≥ÊÉÖÂ†±Ôºà„Åì„Çå„Åå„Å™„ÅÑ„Å®Ë©≥Á¥∞„Éá„Éº„Çø„ÅåË¶ã„Çå„Å™„ÅÑÂ†¥Âêà„Åå„ÅÇ„ÇãÔºâ

# „É≠„Ç±„Éº„Ç∑„Éß„É≥Âà§ÂÆöÁî®„Ç≠„Éº„ÉØ„Éº„Éâ („É¨„Ç¨„Ç∑„ÉºÊ©üËÉΩÁßªÊ§ç)
LOCATION_KEYWORDS = {
    "Event": ["„Ç≥„Éü„Ç±", "C9", "C10", "Â§è„Ç≥„Éü", "ÂÜ¨„Ç≥„Éü", "„Ç¢„Ç≥„Çπ„Çø", "acosta", "Ê±†„Éè„É≠", "„Å®„Å™„Ç≥„Çπ", "Ë∂Ö‰ºöË≠∞", "„Éã„Ç≥Ë∂Ö", "„É©„Ç∞„Ç≥„Çπ", "„ÉØ„É≥„Éï„Çß„Çπ", "„Éõ„Ç≥„Ç≥„Çπ", "„Éì„Éì„Ç≥„Çπ", "„Çπ„Éà„Éï„Çß„Çπ", "a!"],
    "Studio": ["„Çπ„Çø„Ç∏„Ç™", "studio", "ÊíÆ", "ÊíÆÂΩ±‰ºö", "ÂÆÖ„Ç≥„Çπ", "ÂÆ∂", "Ëá™ÊíÆ„Çä", "„Çª„É´„Éï„Ç£„Éº", "Á¨πÂ°ö"]
}

def parse_metric(text):
    """ '1.5‰∏á' „Å™„Å©„ÅÆË°®Ë®ò„ÇíÊï∞ÂÄ§„Å´Â§âÊèõ """
    if not text: return 0
    text = text.replace(',', '').strip()
    try:
        if '‰∏á' in text: return int(float(text.replace('‰∏á', '')) * 10000)
        if 'K' in text: return int(float(text.replace('K', '')) * 1000)
        if 'M' in text: return int(float(text.replace('M', '')) * 1000000)
        return int(''.join(filter(str.isdigit, text)) or 0)
    except: return 0

async def analyze_tweet(url):
    print(f"üîç Analyzing: {url}")

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        context = await browser.new_context(
            storage_state=AUTH_FILE if asyncio.os.path.exists(AUTH_FILE) else None,
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = await context.new_page()

        try:
            await page.goto(url, wait_until="domcontentloaded", timeout=60000)
            await asyncio.sleep(3) # „É¨„É≥„ÉÄ„É™„É≥„Ç∞ÂæÖ„Å°

            # --- 1. Âü∫Êú¨„É°„Éà„É™„ÇØ„ÇπÂèñÂæó („ÅÑ„ÅÑ„Å≠, RP, „Éñ„ÉÉ„ÇØ„Éû„Éº„ÇØ, „Ç§„É≥„Éó„É¨„ÉÉ„Ç∑„Éß„É≥) ---
            # aria-labelÂ±ûÊÄß„Åã„ÇâÊ≠£Á¢∫„Å™Êï∞ÂÄ§„ÇíÊãæ„ÅÜÊà¶Áï•
            metrics = {
                'likes': 0, 'reposts': 0, 'bookmarks': 0, 'views': 0, 'replies': 0
            }

            # data-testid Â±ûÊÄß„Çí‰Ωø„Å£„Å¶ÁâπÂÆö
            likes_elem = await page.query_selector('[data-testid="like"]') or await page.query_selector('[data-testid="unlike"]')
            if likes_elem:
                 # aria-label="1234 likes" „Åã„ÇâÊäΩÂá∫
                 label = await likes_elem.get_attribute("aria-label")
                 metrics['likes'] = parse_metric(label)

            rp_elem = await page.query_selector('[data-testid="retweet"]') or await page.query_selector('[data-testid="unretweet"]')
            if rp_elem:
                 label = await rp_elem.get_attribute("aria-label")
                 metrics['reposts'] = parse_metric(label)

            bm_elem = await page.query_selector('[data-testid="bookmark"]') or await page.query_selector('[data-testid="removeBookmark"]')
            if bm_elem:
                 label = await bm_elem.get_attribute("aria-label")
                 metrics['bookmarks'] = parse_metric(label)
            
            # „Ç§„É≥„Éó„É¨„ÉÉ„Ç∑„Éß„É≥ (Views) - Ë°®Á§∫Â†¥ÊâÄ„ÅåÂ§âÂãï„Åô„Çã„Åü„ÇÅ„ÉÜ„Ç≠„Çπ„ÉàÊé¢Á¥¢
            # ÈÄöÂ∏∏„ÅØ "xyz Views" „ÅÆ„Çà„ÅÜ„Å´Ë°®Á§∫„Åï„Çå„Çã„É™„É≥„ÇØ„Åæ„Åü„ÅØspan„ÇíÊé¢„Åô
            view_elem = await page.query_selector('a[href$="/analytics"]')
            if view_elem:
                text = await view_elem.inner_text() # "1.2‰∏á„ÇíË°®Á§∫" „Å™„Å©
                metrics['views'] = parse_metric(text)
            
            # --- 2. „É¶„Éº„Ç∂„ÉºÊÉÖÂ†± („Éï„Ç©„É≠„ÉØ„ÉºÊï∞) ---
            # Viral EfficiencyË®àÁÆóÁî®
            user_link = await page.query_selector('[data-testid="User-Name"] a')
            follower_count = 0
            screen_name = "Unknown"
            if user_link:
                href = await user_link.get_attribute("href")
                screen_name = href.replace('/', '')
                # „Éó„É≠„Éï„Ç£„Éº„É´„Çí„Éõ„Éê„Éº„Åæ„Åü„ÅØÂà•„Çø„Éñ„ÅßÈñã„Åã„Å™„ÅÑ„Å®Âèñ„Çå„Å™„ÅÑÂ†¥Âêà„Åå„ÅÇ„Çã„Åå„ÄÅ
                # ‰ªäÂõû„ÅØÂçò‰∏ÄÂàÜÊûê„Å™„ÅÆ„Åß„ÄÅ„Éó„É≠„Éï„Ç£„Éº„É´„Éö„Éº„Ç∏„Å∏„Ç∏„É£„É≥„Éó„Åó„Å¶Âèñ„Çã„ÅÆ„ÇÇ„Ç¢„É™
                # (Á∞°ÊòìÁâà„Å®„Åó„Å¶‰∏ÄÊó¶„Çπ„Ç≠„ÉÉ„Éó„Åó„ÄÅÂøÖË¶Å„Å™„ÇâÂÆüË£ÖËøΩÂä†)

            # --- 3. „ÉÜ„Ç≠„Çπ„Éà & „É≠„Ç±„Éº„Ç∑„Éß„É≥Âà§ÂÆö ---
            text_content = ""
            text_elem = await page.query_selector('[data-testid="tweetText"]')
            if text_elem:
                text_content = await text_elem.inner_text()
            
            loc_label = 'Others'
            if any(k in text_content for k in LOCATION_KEYWORDS['Event']): loc_label = 'Event'
            elif any(k in text_content for k in LOCATION_KEYWORDS['Studio']): loc_label = 'Studio/Home'

            # --- 4. ÁîªÂÉèÂàÜÊûê („Ç¢„Çπ„Éö„ÇØ„ÉàÊØî) ---
            images = []
            img_elems = await page.query_selector_all('[data-testid="tweetPhoto"] img')
            aspect_label = 'No Image'
            
            for img in img_elems:
                src = await img.get_attribute("src")
                # „Çπ„Çø„Ç§„É´„Åã„Çâ„Ç¢„Çπ„Éö„ÇØ„ÉàÊØî„ÇíÊé®Ê∏¨
                style = await img.get_attribute("style") # width/height„ÅåÂÖ•„Å£„Å¶„ÅÑ„Çã„Åì„Å®„ÅåÂ§ö„ÅÑ
                # „Åì„Åì„Åß„ÅØÁ∞°ÊòìÁöÑ„Å´1ÊûöÁõÆ„ÅÆURL„ÇíÂèñÂæó
                images.append(src)
            
            if images:
                # ÂÆüÈöõ„ÅÆÁîªÂÉè„Çµ„Ç§„Ç∫ÂèñÂæó„ÅØÂà•ÈÄîÁîªÂÉèÂá¶ÁêÜ„ÅåÂøÖË¶Å„Å†„Åå„ÄÅ
                # „Åì„Åì„Åß„ÅØ„ÄåÁîªÂÉè„Åå„ÅÇ„Çã„Äç„Åì„Å®„Åæ„Åß„ÅØÁ¢∫ÂÆö
                aspect_label = 'Image Found' 

            # --- 5. ÊôÇÈñìÂ∏Ø ---
            time_elem = await page.query_selector('time')
            post_time = "Unknown"
            post_hour = -1
            if time_elem:
                dt_str = await time_elem.get_attribute("datetime")
                post_time = dt_str
                try:
                    dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
                    post_hour = dt.hour
                except: pass

            # --- ÁµêÊûúÂá∫Âäõ ---
            result = {
                'url': url,
                'screen_name': screen_name,
                'metrics': metrics,
                'text_analysis': {
                    'length': len(text_content),
                    'hashtags': text_content.count('#'),
                    'location_type': loc_label
                },
                'image_analysis': {
                    'count': len(images),
                    'urls': images,
                    'aspect_status': aspect_label
                },
                'time_analysis': {
                    'posted_at': post_time,
                    'hour': post_hour
                }
            }
            
            # „Ç≥„É≥„ÇΩ„Éº„É´„Å´Ë¶ã„ÇÑ„Åô„ÅèË°®Á§∫
            print("-" * 40)
            print(f"üìä ÂàÜÊûêÁµêÊûú: {screen_name}")
            print(f"‚ù§Ô∏è Likes: {metrics['likes']:,}")
            print(f"üëÅÔ∏è Views: {metrics['views']:,}")
            print(f"üîñ Saves: {metrics['bookmarks']:,}")
            
            if metrics['views'] > 0:
                eng_rate = round((metrics['likes'] / metrics['views']) * 100, 2)
                print(f"‚ö° Engagement Rate: {eng_rate}% (Likes/Views)")
            
            print(f"üìç Location: {loc_label}")
            print(f"‚è∞ Hour: {post_hour}ÊôÇ")
            print("-" * 40)

            return result

        except Exception as e:
            print(f"‚ùå Error: {e}")
            return None
            
        finally:
            await browser.close()

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python fetch_tweet_data.py <TWEET_URL>")
    else:
        url = sys.argv[1]
        asyncio.run(analyze_tweet(url))
